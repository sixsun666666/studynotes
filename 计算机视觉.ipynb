{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标检测和边界框\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.set_figsize()\n",
    "img = d2l.plt.imread('01_Data/03_catdog.jpg')\n",
    "d2l.plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义在这两种表示之间进行转换的函数\n",
    "def box_corner_to_center(boxes):\n",
    "    \"\"\"从（左上，右下）转换到（中间，宽度，高度）\"\"\"\n",
    "    x1, y1, x2, y2 = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]     \n",
    "    cx = (x1 + x2) / 2\n",
    "    cy = (y1 + y2) / 2\n",
    "    w  = x2 - x1\n",
    "    h  = y2 - y1\n",
    "    boxes = torch.stack((cx,cy,w,h),axis = -1)\n",
    "    return boxes\n",
    "\n",
    "def box_center_to_corner(boxes):\n",
    "    \"\"\"从（中间，宽度，高度）转换到（左上，右下）\"\"\"\n",
    "    cx, cy, w, h = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]\n",
    "    x1 = cx - 0.5 * w\n",
    "    y1 = cy - 0.5 * h\n",
    "    x2 = cx + 0.5 * w \n",
    "    y2 = cy + 0.5 * h\n",
    "    boxes = torch.stack((x1,y1,x2,y2),axis = -1)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图像中狗和猫的边界框\n",
    "dog_bbox, cat_bbox = [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0]  \n",
    "boxes = torch.tensor((dog_bbox,cat_bbox))\n",
    "# boxes 转中间表示，再转回来，等于自己\n",
    "box_center_to_corner(box_corner_to_center(boxes)) == boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将边界框在图中画出\n",
    "def bbox_to_rect(bbox,color):\n",
    "    return d2l.plt.Rectangle(xy=(bbox[0],bbox[1]),width=bbox[2]-bbox[0],     \n",
    "                            height=bbox[3] - bbox[1], fill=False,\n",
    "                            edgecolor=color,linewidth=2)\n",
    "\n",
    "fig = d2l.plt.imshow(img)\n",
    "fig.axes.add_patch(bbox_to_rect(dog_bbox,'blue'))\n",
    "fig.axes.add_patch(bbox_to_rect(cat_bbox,'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目标检测数据集\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.DATA_HUB['banana-detection'] = (d2l.DATA_URL + 'banana-detection.zip','5de25c8fce5ccdea9f91267273465dc968d20d72')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取香蕉检测数据集\n",
    "def read_data_bananas(is_train=True):\n",
    "    \"\"\"读取香蕉检测数据集中的图像和标签\"\"\"\n",
    "    data_dir = d2l.download_extract('banana-detection')\n",
    "    csv_fname = os.path.join(data_dir,\n",
    "                            'bananas_train' if is_train else 'bananas_val',\n",
    "                            'label.csv')\n",
    "    csv_data = pd.read_csv(csv_fname)\n",
    "    csv_data = csv_data.set_index('img_name')\n",
    "    images, targets = [], []\n",
    "    # 把图片、标号全部读到内存里面\n",
    "    for img_name, target in csv_data.iterrows():\n",
    "        images.append(torchvision.io.read_image(os.path.join(data_dir,'bananas_train' if is_train else 'bananas_val',\n",
    "                                                            'images',f'{img_name}')))\n",
    "        targets.append(list(target))\n",
    "    print(\"len(targets)：\",len(targets))\n",
    "    print(\"len(targets[0])：\",len(targets[0]))\n",
    "    print(\"targets[0][0]....targets[0][4]：\",targets[0][0], targets[0][1], targets[0][2], targets[0][3], targets[0][4])    \n",
    "    print(\"type(targets)：\",type(targets))\n",
    "    print(\"torch.tensor(targets).unsqueeze(1).shape：\",torch.tensor(targets).unsqueeze(1).shape) # unsqueeze函数在指定位置加上维数为一的维度   \n",
    "    print(\"len(torch.tensor(targets).unsqueeze(1) / 256)：\", len(torch.tensor(targets).unsqueeze(1) / 256))   \n",
    "    print(\"type(torch.tensor(targets).unsqueeze(1) / 256)：\", type(torch.tensor(targets).unsqueeze(1) / 256))   \n",
    "    return images, torch.tensor(targets).unsqueeze(1) / 256 # 归一化使得收敛更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个自定义Dataset实例\n",
    "class BananasDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"一个用于加载香蕉检测数据集的自定义数据集\"\"\"\n",
    "    def __init__(self, is_train):\n",
    "        self.features, self.labels = read_data_bananas(is_train)\n",
    "        print('read ' + str(len(self.features)) + (f' training examples' if is_train else f'validation examples'))   \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx].float(), self.labels[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为训练集和测试集返回两个数据加载器实例\n",
    "def load_data_bananas(batch_size):\n",
    "    \"\"\"加载香蕉检测数据集\"\"\"\n",
    "    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True),\n",
    "                                            batch_size, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False),\n",
    "                                          batch_size)\n",
    "    return train_iter, val_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取一个小批量，并打印其中的图像和标签的形状\n",
    "batch_size, edge_size = 32, 256\n",
    "train_iter, _ = load_data_bananas(batch_size)\n",
    "batch = next(iter(train_iter))\n",
    "# ([32,1,5]) 中的1是每张图片中有几种类别，这里只有一种香蕉要识别的类别    \n",
    "# 5是类别标号、框的四个参数\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例\n",
    "# pytorch里permute是改变参数维度的函数，\n",
    "# Dataset里读的img维度是[batch_size, RGB, h, w]，\n",
    "# 但是plt画图的时候要求是[h, w, RGB]，所以要调整一下\n",
    "\n",
    "# 做图片的时候，一般是会用一个ToTensor()将图片归一化到【0, 1】，这样收敛更快\n",
    "print(\"原始图片:\\n\", batch[0][0])\n",
    "print(\"原始图片:\\n\", (batch[0][0:10].permute(0,2,3,1)))\n",
    "print(\"归一化后图片:\\n\", (batch[0][0:10].permute(0,2,3,1)) / 255 )\n",
    "imgs = (batch[0][0:10].permute(0,2,3,1)) / 255\n",
    "#imgs = (batch[0][0:10].permute(0,2,3,1))\n",
    "# d2l.show_images输入的imgs图片参数是归一化后的图片\n",
    "axes = d2l.show_images(imgs, 2, 5, scale=2)\n",
    "for ax, label in zip(axes, batch[1][0:10]):\n",
    "    d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 锚框"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
