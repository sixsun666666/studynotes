{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "       def __init__(self):\n",
    "           super(Net, self).__init__()\n",
    "           self.fc1 = torch.nn.Linear(28*28, 128)\n",
    "           self.fc2 = torch.nn.Linear(128, 64)\n",
    "           self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "       def forward(self, x):\n",
    "           x = x.view(-1, 28*28)\n",
    "           x = torch.relu(self.fc1(x))\n",
    "           x = torch.relu(self.fc2(x))\n",
    "           x = self.fc3(x)\n",
    "           return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.39178441225815175\n",
      "Training loss: 0.19045792062526573\n",
      "Training loss: 0.1385348794290792\n",
      "Training loss: 0.11277361777223853\n",
      "Training loss: 0.09443483427008077\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     29\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 创建2x5的子图布局\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 显示每张图片\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 或者，使用grid显示所有图片\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# grid = torchvision.utils.make_grid(images)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# imshow(grid)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(img):\n\u001b[0;32m     20\u001b[0m     img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m     \u001b[38;5;66;03m# unnormalize\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     npimg \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n\u001b[0;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mtranspose(npimg, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 获取一批数据\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 定义一个函数来显示图片\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 显示10张图片\n",
    "images = images.numpy()  # 转换为numpy数组\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)  # 创建2x5的子图布局\n",
    "    imshow(images[i])  # 显示每张图片\n",
    "\n",
    "# 或者，使用grid显示所有图片\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# imshow(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
